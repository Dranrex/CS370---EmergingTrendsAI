{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 2s 0us/step\n",
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,200,842\n",
      "Trainable params: 4,200,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 79s 2ms/step - loss: 1.7286 - accuracy: 0.3926 - val_loss: 1.3828 - val_accuracy: 0.5089\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 84s 2ms/step - loss: 1.3518 - accuracy: 0.5232 - val_loss: 1.2546 - val_accuracy: 0.5714\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 77s 2ms/step - loss: 1.2165 - accuracy: 0.5751 - val_loss: 1.1673 - val_accuracy: 0.5935\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 76s 2ms/step - loss: 1.1275 - accuracy: 0.6054 - val_loss: 1.1005 - val_accuracy: 0.6153\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 77s 2ms/step - loss: 1.0507 - accuracy: 0.6331 - val_loss: 1.0689 - val_accuracy: 0.6299\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 81s 2ms/step - loss: 0.9924 - accuracy: 0.6522 - val_loss: 1.0527 - val_accuracy: 0.6306\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 63s 2ms/step - loss: 0.9387 - accuracy: 0.6736 - val_loss: 1.0497 - val_accuracy: 0.6422\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.8931 - accuracy: 0.6899 - val_loss: 1.0008 - val_accuracy: 0.6611\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.8430 - accuracy: 0.7076 - val_loss: 1.0679 - val_accuracy: 0.6283\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 49s 1ms/step - loss: 0.8154 - accuracy: 0.7178 - val_loss: 0.9925 - val_accuracy: 0.6712\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 54s 1ms/step - loss: 0.7793 - accuracy: 0.7296 - val_loss: 1.0057 - val_accuracy: 0.6670\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 0.7473 - accuracy: 0.7418 - val_loss: 1.0230 - val_accuracy: 0.6693\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 49s 1ms/step - loss: 0.7153 - accuracy: 0.7522 - val_loss: 0.9919 - val_accuracy: 0.6777\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 0.6849 - accuracy: 0.7619 - val_loss: 1.0268 - val_accuracy: 0.6624\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 64s 2ms/step - loss: 0.6646 - accuracy: 0.7673 - val_loss: 1.1717 - val_accuracy: 0.6489\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 57s 1ms/step - loss: 0.6421 - accuracy: 0.7797 - val_loss: 1.0139 - val_accuracy: 0.6813\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 69s 2ms/step - loss: 0.6142 - accuracy: 0.7865 - val_loss: 1.0448 - val_accuracy: 0.6756\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.5953 - accuracy: 0.7949 - val_loss: 1.0641 - val_accuracy: 0.6823\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 0.5748 - accuracy: 0.8030 - val_loss: 1.0496 - val_accuracy: 0.6909\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 53s 1ms/step - loss: 0.5505 - accuracy: 0.8114 - val_loss: 1.1015 - val_accuracy: 0.6699\n",
      "10000/10000 [==============================] - 5s 544us/step\n",
      "Test score: 1.088523530292511\n",
      "Test accuracy: 0.6657999753952026\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "# convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "# network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "# train\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n",
    "epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT,\n",
    "verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 algorithm, which helps identify images, raises important ethical dilemmas. Two major concerns for ethics is bias and fairness. The dataset might not include a wide enough variety of images that represent outliers, leading to biased results against them. It's imperative to include a diverse set of images and get feedback from a team to make sure the AI model is fair and works well.\n",
    "\n",
    "Other ethical considerations for AI are transparency and accountability. It's important for people to understand how the AI makes decisions and where it gets its data from. This builds trust and helps users know how the system works. The AI should also have ways for users to report problems and get help if something goes wrong. \n",
    "\n",
    "Privacy is another major concern with the CIFAR-10 algorithm. While the dataset itself doesn’t have personal information, using similar models in real-world situations could involve collecting data from children. It’s important to protect this data and follow privacy laws like GDPR and COPPA. People are developing a digital footprint when they are first born, which has no precedent for potential ramifications. Children and their parents should know what data is collected and how it’s used. Getting clear consent and securing data storage are vital steps to ensure privacy is maintained.\n",
    "\n",
    "Additionally, regulatory compliance is crucial for protecting user privacy. AI systems must follow laws designed to keep data safe online. Beyond just following these rules, developers should practice ethical data handling. This includes collecting only the necessary data and using techniques to anonymize it, ensuring that subjects identities are protected. By being transparent and careful with data, AI systems can respect user privacy and keep their information secure.\n",
    "\n",
    "https://cifar.ca/wp-content/uploads/2024/04/CIFAR-Responsible-AI-and-Children-EN_Final.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
